\documentclass[a4paper,12pt]{article}
% Math Packages
\usepackage{amsmath,amsfonts}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{amsthm}

% ---------- Environment
\newtheorem{thm}{Theorem}[section]
\newtheorem*{thm*}{Theorem}

\newtheorem{prp}[thm]{Proposition}
\newtheorem*{prp*}{Proposition}

\newtheorem{cor}[thm]{Corollary}
\newtheorem*{cor*}{Corollary}

\newtheorem{lem}[thm]{Lemma}
\newtheorem*{lem*}{Lemma}

\newtheorem{dfn}[thm]{Definition}
\newtheorem*{dfn*}{Definition}

\theoremstyle{remark}
\newtheorem*{prf}{Proof}

\theoremstyle{definition}
\newtheorem*{rem*}{Remark}
\newtheorem{rem}[thm]{Remark}

\theoremstyle{definition}
\newtheorem{ex}[thm]{Example}
\newtheorem*{ex*}{Example}

\theoremstyle{definition}
\newtheorem{exe}[thm]{Exercise}
% --------- Environment

% --------- macros
\newcommand{\ip}[2]{\left<#1, #2 \right>}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\norm}[1]{\left\| #1 \right\|}
\newcommand{\ev}[1]{\mathrm{ev}_{#1}}
\newcommand{\adj}[1]{#1^{\star}}
\newcommand{\fin}{\hfill \( \triangleleft \) }

\begin{document}
\section*{What's this?}
This document collects basic results on Reproducing Kernel Hilbert Space that are useful in the context of machine learning, aimed at readers with a basic knowledge of functional analysis. The content relies heavily on the existing literature listed in the bibliography, in particular \cite{Berlinet:RKHS} \cite{Christmann-Steinwart:SVM}.
\cite{Cucker-Zhou:Learning-Theory}
\cite{Paulsen-Raghupathi:Intro-RKHS}
\cite{Schlkopf-Smola:Learning-with-kernels}
\section*{Overview}

\tableofcontents
\section{Basic Property of RKHS}
\subsection{Properties of Reproducing Kernel}
\begin{dfn}[Reproducing kernel]
	Let \( E \) be a nonempty set. A function \( K \) defined by
	\[
		K:E \times E \ni (x,y) \mapsto K(x,y) \in \mathbb{F}
	\]
	is called a reproducing kernel of a Hilbert space \( H \) of functions on \( E \) if it satisfies the following conditions:
	\begin{itemize}
		\item[(a)] \( K(\cdot, x) \in H \) for every \( x \in E \)
		\item[(b)]  \( \ip{f}{K(\cdot, x)}_H = f(x) \) for every \( x \in E \) and every \( f \in H \).
	\end{itemize}
	Such a Hilbert space, associated with its reproducing kernel, is called a reproducing kernel hilbert space, and is denoted by \( (H,K) \).
\end{dfn}

\begin{thm}[Characterization of RKHS]\label{chara RKHS}
	A Hilbert space \( H \) of functions on a nonempty set \( E \) admits a reproducing kernel \( K \) if and only if all evaluation functionals \( \{\ev{x} \} _{x \in E} \) are continuous on \( H \).
\end{thm}
\begin{prf}
	Suppose \( (H,K) \) is a RKHS.
	For \( x \in E \) and for \( f \in H \) we have
	\[
		\abs{\ev{x}(f)} = \abs{f(x)} = \abs{ \ip{f}{K(\cdot , x)}} \le \norm{f} \norm{K(\cdot,x )} \le \norm{f} K(x,x) ^{1/2} \to 0
	\]
	as \(  \norm{f}\to 0 \). Thus, \( \ev{x} \) is continuous linear functional (with norm \( K(x,x) ^{1/2} \)).

	Conversely, if \( \ev{x}:H \ni f \mapsto f(x) \in \mathbb{F} \) is continuous, then, by Riesz's representation theorem, there exists \( r_x \in H\) such that
	\begin{equation*}
		\ip{f}{r_x} = f(x)
	\end{equation*}
	for every \( f \in H \). If this happens for every \( x \in E \), then \( K(x,y):=r_x(y) \) is a reproducing kernel of \( H \).
	\qed\end{prf}

\begin{cor}\label{norm convergence implies pointwiese convergence}
	Every convergent sequence in RKHS converges pointwise to the same limit.
\end{cor}
\begin{prf}
	\( \abs{ f_n(x) - f(x)} = \abs{\ev{x}(f_n - f)} \to 0 \) when \( f_n \to f \) in norm by continuity of evaluation functional.
	\qed\end{prf}

\begin{prp}(Uniqueness of \( H \) and \( K \))\label{Density and Unique of RKHS}

	\begin{itemize}
		\item[(a)] The subspace \( H_0 \) spanned by \( \{K(\cdot ,x) \} _{x \in E} \) is dense in \( H \).
		\item[(b)] A Hilbert space admits at most one reproducing kernel.
		\item[(c)] A function \( K:E \times E \to \mathbb{F} \) is a reproducing kernel for at most one Hilbert space.
	\end{itemize}
\end{prp}
\begin{prf}
	For density of \( H_0 \), observe \( f \in H \) fulfills \( f \perp H_0 \) if and only if
	\begin{equation*}
		\ip{f}{K(\cdot ,x)}_H = f(x)=0
	\end{equation*}
	for every \( x \in E \), which is the case precisely when \( f \equiv 0 \). To check (b), suppose \( K_1 \) and \( K_2 \) qualify as a reproducing kernel of \( H \). By definition,
	\begin{equation*}
		f(x) = \ip{f}{K_1(\cdot ,x)}_H =\ip{f}{K_2(\cdot ,x)}_H
	\end{equation*}
	for every \( x \in E \), and hence
	\begin{equation*}
		\ip{f}{K_1(\cdot ,x)- K_2(\cdot ,x)}_H = 0
	\end{equation*}
	for every \( f \in H \) and \( x \in E \). From this we conclude \( K_1 =K_2 \).
	Finally suppose that \( (H_1,K) \) and \( (H_2,K) \) are two RKHSs.
	Pick \( f \in H_1 \). By (a), there is \( \{f_n\} \subset H_0 \subset H_1 \cap H_2 \) such that \( f_n \to f \) in \( H_1 \)-norm. Since \( \{f_n\} \) is also an Cauchy sequence in \( H_2 \), it admits a limit \( g \in H_2 \). But Corollary\ref{norm convergence implies pointwiese convergence} implies \( f=g \), and hence \( f \in H_2 \). We then have
	\begin{equation*}
		\norm{f}_{H_1}
		= \lim_{n \to \infty} \norm{f_n}_{H_1}
		=\lim_{n \to \infty} \norm{f_n}_{H_0}
		=\lim_{n \to \infty} \norm{f_n}_{H_2}
		=\norm{f}_{H_2}.
	\end{equation*}
	Therefore, \( H_1 \) is isometrically included in \( H_2 \). Symmetry thus shows that both Hilbert spaces coincide.
	\qed\end{prf}

\begin{prp} (Representation of RK in terms of evaluation functional)\label{Representation of RK in terms of ev}
	In arbitrary RKHS \( (H,K) \), the reproducing kernel \( K:E \times E \to \mathbb{F} \) always fulfills the identity
	\begin{equation*}
		K(x,y) = \ip{\ev{y}}{\ev{x}}_{\adj{H}}
	\end{equation*}
	for all \( x,y \in E \), where \( \adj{H} \) is the dual space of \( H \).
\end{prp}
\begin{prf}
	It suffices to show that a function \( K \) \textit{defined} by the above equation is also a reproducing kernel.
	Let a mapping \( I:\adj{H}\to H \) be the isometric anti-linear surjection,  guaranteed by Riesz's Representation Theorem, that assigns to every functional in \( \adj{H} \) the corresponding representor in \( H \), i.e., \( \adj{g}(f)=\ip{f}{I \adj{g}}_H \) for all \( f \in H \) and \( g \in \adj{H} \), where \( \adj{g} \) is the adjoint of \( g \). Then we have
	\begin{equation*}
		K(x,y) = \ip{\ev{y}}{\ev{x}}_{\adj{H}}
		= \ip{I \ev{y}}{I \ev{x}}_H
		= \ev{x} \left( \ev{y} \right) = \left( I \ev{y} \right)(x),
	\end{equation*}
	for all \( x,y \in E \), and hence \( K(\cdot ,y) = I \ev{y} \in H \). From this it follows that
	\begin{equation*}
		f(y) = \ev{y}(f) = \ip{f}{I \ev{y}}_H = \ip{f}{K(\cdot ,y)}
	\end{equation*}
	for all \( y \in E \). Thus, \( K \) is a reproducing kernel.
	\qed\end{prf}

\subsection{RKHS of a kernel}

\begin{dfn} (Kernel, Feature Space, Feature Map)
	A function \( K:E \times E \to \mathbb{F} \) is called a kernel if there is a \( \mathbb{F}\)-Hilbert space \( H \) and a mapping \( \varphi:E \to H \) such that
	\begin{equation*}
		K(x,y) = \ip{\varphi(y)}{\varphi(x)}_H
	\end{equation*}
	for all \( x,y \in E \).
	Such a \( \varphi \) is called a feature map, and \( H \) a feature space.
\end{dfn}
\begin{rem}
	Proposition\ref{Representation of RK in terms of ev} tells us that every RK is indeed a kernel, and that the map \( E \ni x \mapsto \ev{x} \in \adj{H} \) is a feature map with a feature space \( \adj{H} \).
	Every RKHS \( (H,K) \) also admits a more simple feature map \( \varphi_K \), called a canonical feature map, given by
	\begin{equation*}
		\varphi_K:E \ni x \mapsto K(\cdot ,x) \in H.
	\end{equation*}
	This clearly shows that, given a kernel, neither feature space nor feature map are uniquely determined.
	\fin\end{rem}

\begin{dfn} (Positive definite function)
	Let \( E \) be a nonempty set.
	A function \( K: E \times E \to \mathbb{C} \) is called positive definite if for any \( n \in \mathbb{N} \) and for any \( a \in \mathbb{C}^n \) and \( x \in E^n \) there holds
	\begin{equation}
		\sum_{i=1}^{n} \sum_{j=1}^{n} a_i \overline{a_j}K(x_i,x_j) \ge 0, \label{pd eq}
	\end{equation}
	where \( \overline{c} \) is the complex conjugate of \( c \).
\end{dfn}

\begin{prp} (Characterization of real positive definite function)\label{chara real pd}
	A real function \( K:E \times E \to \mathbb{R} \) is positive definite if and only if it has the following properties:
	\begin{itemize}
		\item[(a)] \( K \) is symmetric.
		\item[(b)] The defining inequality (\ref{pd eq}) holds for any \( \alpha \in \mathbb{R}^n \) instead of \( \mathbb{C}^n \).
	\end{itemize}
\end{prp}

\begin{cor} (Kernel is positive definite)\label{kernel is pd}
	A kernel is positive definite.
\end{cor}
\begin{prf}
	For the case \( \mathbb{F}=\mathbb{C} \), we have
	\begin{equation*}
		\sum_{i=1}^{n} \sum_{j=1}^{n} a_i \overline{a_j} \overline{K(x_i,x_j)}
		= \sum_{i=1}^{n} \sum_{j=1}^{n} a_i \overline{a_j} \ip{\varphi(x_i)}{\varphi(x_j)}
		= \norm{\sum_{i=1}^{n} a_i \varphi(x_i) }^2 \ge 0,
	\end{equation*}
	and hence \( \overline{K} \) as well as \( K \) are positive definite.
	\qed\end{prf}

\begin{prp}
	Every positive definite function \( K:E \times E \to \mathbb{C} \) satisfies
	\begin{itemize}
		\item[(a)] \( K(x,x) \ge 0 \) for every \( x \in E \)
		\item[(b)] \( K(x,y)=\overline{K(y,x)} \) for every \( x,y \in E \)
		\item[(c)] \( \overline{K} \) is also positive definite, and conversely
		\item[(d)] \( \abs{K(x,y)} \le K(x,x)K(y,y) \) for every \( x,y \in E \).
	\end{itemize}
\end{prp}
\begin{prf}
	(a) and (c) clearly hold. For \( \alpha, \beta \in \mathbb{C} \) and \( x,y \in E \), we have
	\begin{equation*}
		g(\alpha,\beta) := \abs{\alpha}^2 K(x,x) + \alpha \overline{\beta}K(x,y) + \overline{\alpha}\beta K(y,x) + \abs{\beta}^2 K(y,y) \ge 0.
	\end{equation*}
	Choose \( \alpha=\beta=1 \) and \( \alpha = i \), \( \beta=1 \) to get
	\begin{equation*}
		\begin{aligned}
			K(x,y) + K(y,x) = g(1,1) - K(x,x) - K(y,y)     & =: A \in \mathbb{R}  \\
			i K(x,y) - i K(y,x) = g(i,1) - K(x,x) - K(y,y) & =: B \in \mathbb{R}.
		\end{aligned}
	\end{equation*}
	Therefore,
	\begin{equation*}
		\begin{aligned}
			2 K(y,x) & = A + iB  \\
			2 K(x,y) & = A - iB,
		\end{aligned}
	\end{equation*}
	which proves (b). Finally, for \( x,y \in E \) with \( K(x,y) \neq 0 \) and for \( r \in \mathbb{R} \), (b) gives
	\begin{equation*}
		0 \ge g(r,K(x,y)) = r ^2 K(x,x) + 2r \abs{K(x,y)}^2 + \abs{K(x,y)}^2K(y,y).
	\end{equation*}
	As RHS is quadratic in \( r \), it must satisfy
	\begin{equation*}
		\abs{K(x,x)}^4 - \abs{K(x,y)}^2K(x,x)K(y,y) \le 0,
	\end{equation*}
	from which (d) follows.
	\qed\end{prf}

\begin{thm} (RKHS generated by inner product space)\label{RKHS generated by ip sp}
	Let \( H_0 \) be the subspace of \( \mathbb{F}^E \), equipped with an inner product \( \ip{\cdot }{\cdot }_{H_0} \) with norm \( \norm{\cdot }_{H_0} \).
	Then there exists unique RKHS \( (H,K) \) that extends \( H_0 \) in the sense that
	\begin{itemize}
		\item[(a)] \( H_0 \subset H \subset \mathbb{F}^E\) and the subspace topology of \( H_0 \) in \( H \) coincides with the topology of \( (H_0, \norm{\cdot }_{H_0}) \)
	\end{itemize}
	if and only if \( H_0 \) satisfies the following conditions:
	\begin{itemize}
		\item[(b)] every evaluation functional \( \ev{x} \) is continuous in \( (H_0, \norm{\cdot }_{H_0})\)
		\item[(c)] any Cauchy sequence \( \{f_n\} \subset H_0 \) converging pointwise to 0 converges to 0 also in \( H_0 \)-norm.
	\end{itemize}
\end{thm}
\begin{prf}
	Suppose such an extension \( H \) exists. \( H \) satisfies (b) by Theorem\ref{chara RKHS}.
	Since \( H \) is complete, a Cauchy sequence \( \{f_n\} \subset H_0\) tends to some \( f \), for which we have
	\begin{equation*}
		f(x) = \ev{x}(f) = \lim_{n \to \infty} \ev{x}(f_n) = \lim_{n \to \infty} f_n(x) = 0
	\end{equation*}
	for every \( x \in E \). Therefore, \( f \) is identically 0.

	Conversely, suppose (b)(c) hold. Let \( H \) be the set of all functions \( f \in \mathbb{F}^E \) for which there exists a Cauchy sequence \( \{f_n\} \subset H_0 \) converging pointwise to \( f \). Clearly, \( H_0 \subset H \subset \mathbb{F}^E \). The rest of proof consists of the following Lemmas.
	\qed\end{prf}

\begin{lem}\label{construction of inner product}
	Let \( f,g \in H \) and let \( \{f_n\} \) and \( \{g_n\} \) be two Cauchy sequences in \( H_0 \) that converge pointwise to \( f \) and \( g \) respectively.
	\begin{itemize}
		\item[(A)] The sequence \( \ip{f_n}{g_n}_{H_0} \) is convergent.
		\item[(B)] The limit \( \lim_{n \to \infty} \ip{f_n}{g_n}_{H_0} \) depends solely on \( f \) and \( g \), independent of the choice of \( f_n \) and \( g_n \).
		\item[(C)] \( \ip{f}{g}_H := \lim_{n \to \infty} \ip{f_n}{g_n}_{H_0} \) is an inner product on \( H \).
	\end{itemize}
\end{lem}
\begin{prf}
	It follows from the definition of \( f_n \) and \( g_n \) that
	\begin{equation*}
		\begin{aligned}
			\abs{\ip{f_n}{g_n}_{H_0} - \ip{f_m}{g_m}_{H_0}}
			 & = \abs{\ip{f_n - f_m}{g_n} - \ip{f_m}{g_n - g_m}}                    \\
			 & \ge \norm{g_n} \norm{f_n - f_m} + \norm{f_m} \norm{g_n - g_m} \to 0,
		\end{aligned}
	\end{equation*}
	which proves (A). In order to verify (B), suppose \( \{f_n'\} \) and \( \{g_n'\} \) are also such approximating sequences. We then similarly deduce that
	\begin{equation*}
		\abs{\ip{f_n}{g_n} - \ip{f_n'}{g_n'}} \le \norm{g_n}\norm{f_n- f_n'} + \norm{f_n'}\norm{g_n - g_n'}.
	\end{equation*}
	\( \{f_n- f_n'\} \) and \( \{g_n-g_n'\} \) are Cauchy sequences tending pointwise to 0. Thus, assumption (c) gives \( \norm{f_n-f_n'}\to 0 \) and \( \norm{g_n - g_n'}\to 0 \). So, (A) and (B) show that \( \ip{f}{g}_H \) is well-defined. Note that if \( \ip{f}{f}_H = 0\), then for every \( x \in E \)
	\begin{equation*}
		f(x) = \ev{x}(f) = \lim_{n \to \infty} \ev{x}(f_n) = \lim_{n \to \infty} f_n(x) = 0,
	\end{equation*}
	and hence \( f \equiv 0 \). As the symmetry, positivity, linearity are quite obvious, we conclude that (C) is true.
	\qed\end{prf}

\begin{lem}\label{Lemma density of H0 in H}
	\begin{itemize}
		\item[(A)] Let \( f \in H \) and let \( \{f_n\} \subset H_0 \) be a Cauchy sequence converging pointwise to \( f \). Then \( f_n \to f \) also in \( H \)-norm.
		\item[(B)] \( H_0 \) is dense in \( H \).
	\end{itemize}
\end{lem}
\begin{prf}
	(A): Fix \( \epsilon>0 \). Choose \( N \in \mathbb{N}\) large enough so that
	\begin{equation*}
		\norm{f_n - f_m}_{H_0} < \epsilon
	\end{equation*}
	for all \( n,m >N \). For fixed \( n \), \( \{f_n-f_m\}_{m \in \mathbb{N}} \) is a Cauchy sequence converging pointwise to \( f_n-f \). Therefore, by definition of \( \ip{\cdot }{\cdot }_H \),
	\begin{equation*}
		\norm{f-f_n}_H = \lim_{n \to \infty}\norm{f_n - f_m}_{H_0} \le \epsilon.
	\end{equation*}
	(B) is obvious from (A).
	\qed\end{prf}

\begin{lem}\label{continuity of evaluation}
	Every evaluation functional \( \ev{x} \) is continuous on \( H \).
\end{lem}
\begin{prf}
	Fix \( x \in E \). As a linear functional \( \ev{x} \) is assumed to be continuous on \( H_0 \), it admits unique continuous extension \( T_x \) onto the closure of \( H_0 \) in \( H \), that is, onto whole \( H \), where we use the assumption (a) and Lemma2(B). \( T_x \) is also the evaluation functional on \( H \). Indeed, for \( f \) and \( f_n \) as in Lemma\ref{Lemma density of H0 in H}, we have
	\begin{equation*}
		T_x(f) = \lim_{n \to \infty} \ev{x}(f_n) = \lim_{n \to \infty}f_n(x) = f(x).
	\end{equation*}
	\qed\end{prf}

\begin{lem}
	\( H \) is a RKHS satisfying (a) in Theorem\ref{RKHS generated by ip sp}. Consequently, \( H \) is isomorphic to the completion of \( H_0 \) and thus unique RKHS that meets the requirement.
\end{lem}
\begin{prf}
	We first prove that \( H \) is actually a RKHS. In light of Theorem\ref{chara RKHS} and Lemma\ref{continuity of evaluation}, it suffices to show that \( H \) is complete. Let \( \{f_n\} \) be a Cauchy sequence in \( H \). Let \( x \in E \). \( \{f_n(x)\} \) is also a Cauchy in \( \mathbb{F} \), and hence converges to some \( f(x) \). By Lemma\ref{Lemma density of H0 in H}, for every \( n \in \mathbb{N} \), there is \( g_n \in H_0 \) such that \( \norm{f_n-g_n}_H < n ^{-1}\). In view of the inequality
	\begin{equation*}
		\norm{f-f_n}_H \le \norm{f-g_n}_H + \norm{g_n- f_n}_H,
	\end{equation*}
	it suffices to prove that \( \norm{f-g_n}_H \to 0 \). To this end, we show that \( \{g_n\} \) is a Cauchy sequence converging pointwise to \( f \) (and then apply Lemma\ref{Lemma density of H0 in H}).

	For fixed \( x \in E \), we have
	\begin{equation*}
		\begin{aligned}
			\abs{g_n(x)-f(x)} & \le \abs{g_n(x)-f_n(x)} + \abs{f_n(x)-f(x)}       \\
			                  & = \abs{\ev{x}(g_n-f_n)} + \abs{f_n(x)-f(x)} \to 0
		\end{aligned}
	\end{equation*}
	as \( n \to \infty \), since \( \ev{x} \) is continuous and \( f_n(x)\to f(x) \) pointwise. Moreover,
	\begin{equation*}
		\begin{aligned}
			\norm{g_n-g_m}_{H_0} & = \norm{g_n-g_m}_{H}                                 \\
			                     & \le \norm{g_n-f_n} + \norm{f_n-f_m} + \norm{g_m-f_m} \\
			                     & = n ^{-1} + \norm{f_n-f_m} + n ^{-1} \to 0
		\end{aligned}
	\end{equation*}
	when \( n,m \to \infty \), as required. \( H \) is isomorphic to the completion of \( H_0 \) since \( H_0 \) is dense in \( H \). Finally, suppose \( H' \) is also an qualifying RKHS. As \( H \) is isomorphic to \( H' \) there exists an isometric isomorphism between them. Furthermore, by Lemma\ref{Lemma density of H0 in H} and Lemma\ref{continuity of evaluation}, they share the same evaluation functionals \( \{\ev{x} \} _{x \in E} \) and hence the same reproducing kernel by Proposition\ref{Representation of RK in terms of ev}. Thus, they must coincide by Proposition\ref{Density and Unique of RKHS}.
	\qed\end{prf}

\begin{thm} (Moore-Aronszajn)\label{Moore Theorem}
	For arbitrary positive definite function \( K:E \times E \to \mathbb{F} \), there exists unique RKHS \( H \) that has \( K \) as its reproducing kernel. Moreover, the subspace \( H_0 \) spanned by \( \{K(\cdot ,x)\}_{x \in E} \) is dense in \( H \).
\end{thm}
\begin{prf}
	Define an inner product \( \ip{\cdot}{\cdot }_{H_0} \) on \( H_0 \) by setting
	\begin{equation*}
		\ip{f}{g}_{H_0} := \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \beta_i K(y_i,x_i),
	\end{equation*}
	where \( f= \sum_{i=1}^{n} \alpha_i K(\cdot ,x_i) \) and \( g= \sum_{j=1}^{n} \alpha_i K(\cdot ,y_i) \). Let us observe
	\begin{equation*}
		\sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \beta_i K(y_i,x_i)
		= \sum_{i=1}^{n}\alpha_i \overline{g(x_i)} = \sum_{j=1}^{n} \overline{\beta_i}f(y_j),
	\end{equation*}
	and therefore that the value \( \ip{f}{g}_{H_0} \) is determined by solely by \( f \) and \( g \), independent of the choice of representing linear combination. Choosing \( g=K(\cdot ,x) \) yields
	\begin{equation*}
		\ip{f}{K(\cdot ,x)}_{H_0} = \sum_{i=1}^{n} \alpha_i \overline{h(x_i)}
		= \sum_{i=1}^{n} \alpha_i K(x,x_i) = f(x).
	\end{equation*}
	So, \( K \) fulfills the reproducing identity under \( \ip{\cdot }{\cdot }_{H_0} \). In particular,
	\begin{equation*}
		\norm{K(\cdot ,z)}_{H_0} = \ip{K(\cdot ,x)}{K(\cdot ,x)}_{H_0} = K(x,x) \ge 0.
	\end{equation*}
	From this definiteness of \( \ip{\cdot }{\cdot }_{H_0} \) follows; indeed, if \( \ip{f}{f}_{H_0} = 0 \), then we have
	\begin{equation*}
		\abs{f(x)} = \abs{\ip{f}{K(\cdot ,x)}} \le \ip{f}{f}^{1/2}K(x,x)^{1/2}=0,
	\end{equation*}
	for every \( x \in E \), implying \( f \equiv 0 \). We then conclude that \( \ip{\cdot }{\cdot }_{H_0} \) is in fact an inner product on \( H_0 \) as the other requirements are easy to check.

	We now show that \( H_0 \) fulfills the conditions of Theorem\ref{RKHS generated by ip sp}. First, each \( \ev{x} \) is continuous on \( H_0 \); in fact, for \( f, g \in H_0 \),
	\begin{equation*}
		\abs{\ev{x}(f)- \ev{x}(g)} = \abs{\ip{f-g}{K(\cdot ,x)}_{H_0}} \le \norm{f-g}_{H_0}K(x,x)^{1/2}
	\end{equation*}
	for every \( x \in E \). To verify the other condition, let \( \{f_n\} \) be a Cauchy sequence in \( H_0 \) converging pointwise to 0. Let \( B>0 \) be an upper bound for \( \norm{f_n}_{H_0} \). For \( \epsilon>0 \) and large \( N \in \mathbb{N} \) we have
	\begin{equation*}
		\norm{f_n - f_N} < \frac{\epsilon}{B}
	\end{equation*}
	for all \( n \ge N \). We may write
	\begin{equation*}
		f_N = \sum_{i=1}^{k} K(\cdot ,x_i)
	\end{equation*}
	for some \( \alpha_i \in \mathbb{F} \) and \( x_i \in E \), and for some fixed \( k \). It then follows that
	\begin{equation*}
		\norm{f_n}^2_{H_0} = \ip{f_n- f_N}{f_n}_{H_0} + \ip{f_N}{f_n}_{H_0}
		\le \epsilon + \sum_{i=1}^{k}f(x_i)
	\end{equation*}
	for \( n \ge N \), and hence \( \norm{f_n}\to 0 \) as \( n \to 0 \). Therefore, there is a RKHS \( H \) that has \( H_0 \) as a dense subspace.
	Furthermore, for each \( f \in H \) there is \( \{f_n\} \subset H_0 \) such that \( f_n \to f \) pointwise as well as in \( H \)-norm, for which we have
	\begin{equation*}
		f(x) = \lim_{n \to \infty} f_n(x)= \lim_{n \to \infty} \ip{f_n}{K(\cdot ,x)}_{H_0} = \ip{f}{K(\cdot ,x)}_H,
	\end{equation*}
	for every \( x \in E \). Thus, \( K \) is a reproducing kernel of \( H \). Uniqueness follows from Proposition\ref{Density and Unique of RKHS}.
	\qed\end{prf}

\begin{thm} (Characterization of positive definite function)\label{Characterization of pd}
	A function \( K:E \times E \to \mathbb{F} \) is positive definite (and thus a reproducing kernel of some RKHS) if and only if \( K \) is a kernel, that is, if and only if there exists some mapping \( \varphi \) of \( E \) into some  \( \mathbb{F} \)-Hilbert space \( H \) such that
	\begin{equation*}
		K(x,y) = \ip{\varphi(y)}{\varphi(x)}_H
	\end{equation*}
	for all \( x,y \in E \).
\end{thm}
\begin{prf}
	If \( (H,K) \) is the RKHS generated by positive definite function \( K \), then the canonical feature map \( \varphi_K:E \ni x \mapsto K(\cdot ,x) \in H \) obviously qualifies. The converse follows from Corollary\ref{kernel is pd}.
	\qed\end{prf}

\begin{rem}
	Theorem\ref{Characterization of pd} implies that RKHS \( (H,K) \) is a natural feature space.
	\fin\end{rem}

Theorem\ref{Characterization of pd} is a powerful tool to construct a positive definite function as well as to prove a given function is a kernel \textit{if we can find an appropriate feature space}, as the following example illustrates.
\begin{ex}
	Let us show that \( K(x,y) = \min(x,y),\,x,y \in \mathbb{R}_{+} \) is positive definite.
	Let H:=\( L^2(\mathbb{R}_{+}, \mu) \) be the space of all square integrable functions on \( \mathbb{R}_{+} \) with respect to a \( \sigma \)-finite measure \( \mu \). It is well-known that \( H \) is a Hilbert space with the inner product \( \ip{f}{g}_H := \int_{\mathbb{R}_{+}} f \overline{g} d \mu\). Then we have
	\begin{equation*}
		K(x,y) = \int_{\mathbb{R}_{+}} 1_{[0,y]}(t) 1_{[0,x]}(t) d \mu(t) = \ip{\varphi(y)}{\varphi(x)}_H,
	\end{equation*}
	where \( \varphi:E \ni x \mapsto 1_{[0,x]}(\cdot ) \in H \) is the feature map, and \( 1_A(\cdot ) \) is the indicator function of \( A \). Therefore, \( K \) is positive definite. \fin
\end{ex}

The next Theorem relates a feature map (therefore a kernel) and the RKHS the corresponding positive definite function generates.
\begin{thm} (RKHS generated by feature map)
	Let \( E \neq \emptyset \). Suppose \( K \) is a positive definite kernel with a feature space \( H_0 \) and a feature map \( \varphi_0 :E \to H_0 \). Then the Hilbert space
	\begin{equation*}
		H:= \{f:E \to \mathbb{F} \mid \exists w \in H_0 \,:\, f(x)=\ip{w}{\varphi_0(x)}_{H_0}\, \forall x \in E \}
	\end{equation*}
	equipped with the norm
	\begin{equation*}
		\norm{f}_H := \inf \{\norm{w}_{H_0} \,:\, w \in H_0,\, f = \ip{w}{\varphi_0(\cdot )}_{H_0}\}
	\end{equation*}
	is the RKHS generated by \( K \), and \( H \) and \( \norm{\cdot }_H \) are determined independent of the choice of feature space \( H_0 \) and feature map \( \varphi_0 \). Moreover, the function
	\begin{equation*}
		V : H_0 \ni w \mapsto \ip{w}{\varphi_0(\cdot )}_{H_0} \in H
	\end{equation*}
	is an isometric isomorphism on \( (\ker V)^{\perp} \).
\end{thm}
\begin{prf}
	In light of Theorem\ref{Moore Theorem}, it suffices to prove that \( H \) is RKHS with reproducing kernel \( K \). The property of \( V \) are automatically obtained in the process. It is easy to verify that \( \norm{\cdot }_H \) is actually a norm on \( H \). As \( \ker V \) is closed subspace of \( H_0 \), we get the orthogonal decomposition \( H_0 = \ker V \oplus \left( \ker V \right)^{\perp} \). Let \( H_1 := \left( \ker V \right)^{\perp} \) and the restriction of \( V \) onto \( H_1 \) be denoted by \( V_1 \). Since every \( f \in H \) can be written as \( f = V(w_0+w_1) = V_1 w_1 \), with \( w_0 \in \ker V \), \( w_1 \in H_1 \),  we see that \( V_1 :H_1 \to H \) is an isomorphism. Similarly, we have
	\begin{equation*}
		\begin{aligned}
			\norm{f}_H
			 & = \inf \{ \norm{w_0+w_1}_{H_0} ^2 \,:\, w_0 \in \ker V, w_1 \in H_1, w_0 + w_1 \in V^{-1}(\{f\})\}     \\
			 & = \inf \{ \norm{w_0}^2 + \norm{w_1}^2 \,:\, w_0 \in \ker V, w_1 \in H_1, w_0 + w_1 \in V^{-1}(\{f\})\} \\
			 & = \norm{V_1^{-1}(f)}_{H_1} \left( := \norm{V_1^{-1}(f)}_{H_0} \right).
		\end{aligned}
	\end{equation*}
	From this equation, we conclude that \( V_1 :H_1 \to H \) is an isometric isomorphism, as required, and that \( H \) is a Hilbert space.

	It remains to show that \( K \) qualifies as the reproducing kernel. Observe
	\begin{equation*}
		K(\cdot ,x) = \ip{\varphi_0(x)}{\varphi_0(\cdot )}_{H_0} = V \varphi_0(x)\in H.
	\end{equation*}
	Moreover, the fact \( \ip{w}{\varphi_0(x)}_{H_0} = 0 \) for all \( w \in \ker V \) implies
	\begin{equation*}
		f(x) = \ip{V_1^{-1}f}{\varphi_0(x)}_{H_0} = \ip{f}{V \varphi_0(x)}_H = \ip{f}{K(\cdot ,x)}_H
	\end{equation*}
	for all \( f \in H \) and \( x \in E \).
	\qed\end{prf}

\subsection{Basic Properties of Kernel}

\section{Reconstruction of RKHS}

\subsection{Reconstruction via Restriction}
\subsection{Reconstruction via Operator}
\subsection{Reconstruction via Sum and Product}

\section{Inheritance from Kernel to RKHS}
\subsection{Measurability of RKHS}
\subsection{Separability of RKHS}

\section{Mercer Representation}
\section*{Further Readings}
\bibliographystyle{plain}
\bibliography{ref}
\end{document}