\documentclass[a4paper,12pt]{article}
% Math Packages
\usepackage{amsmath,amsfonts}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{url}

% ---------- Environment
\newtheorem{thm}{Theorem}[section]
\newtheorem*{thm*}{Theorem}

\newtheorem{prp}[thm]{Proposition}
\newtheorem*{prp*}{Proposition}

\newtheorem{cor}[thm]{Corollary}
\newtheorem*{cor*}{Corollary}

\newtheorem{lem}[thm]{Lemma}
\newtheorem*{lem*}{Lemma}

\newtheorem{dfn}[thm]{Definition}
\newtheorem*{dfn*}{Definition}

\theoremstyle{remark}
\newtheorem*{prf}{Proof}

\theoremstyle{definition}
\newtheorem*{rem*}{Remark}
\newtheorem{rem}[thm]{Remark}

\theoremstyle{definition}
\newtheorem{ex}[thm]{Example}
\newtheorem*{ex*}{Example}

\theoremstyle{definition}
\newtheorem{exe}[thm]{Exercise}

% --------- Environment

% --------- macros
\newcommand{\ip}[2]{\left<#1, #2 \right>}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\norm}[1]{\left\| #1 \right\|}
\newcommand{\ev}[1]{\mathrm{ev}_{#1}}
\newcommand{\adj}[1]{#1^{\star}}
\newcommand{\fin}{\hfill \( \triangleleft \) }

\let\Re\relax
\DeclareMathOperator{\Re}{Re}
\let\Im\relax
\DeclareMathOperator{\Im}{Im}


\title{A Theory on Reproducing Kernel Hilbert Space for Machine Learning} 
\author{\url{https://github.com/Shena4746/RKHS-for-ML}}
\date{2020/05/14}

\begin{document}
\maketitle
\section*{What's this?}
This document collects basic results on Reproducing Kernel Hilbert Space that are useful in the context of machine learning, aimed at readers with a basic knowledge of functional analysis. The content relies heavily on the existing literature listed in the bibliography, in particular \cite{Berlinet:RKHS} \cite{Christmann-Steinwart:SVM}.
\cite{Cucker-Zhou:Learning-Theory}
\cite{Paulsen-Raghupathi:Intro-RKHS}
\cite{Schlkopf-Smola:Learning-with-kernels}

\section*{Overview}

\tableofcontents
\clearpage
\section{Basic Property of RKHS}
\subsection{Properties of Reproducing Kernel}
\begin{dfn}[Reproducing kernel]
	Let \( E \) be a nonempty set. A function \( K \) defined by
	\[
		K:E \times E \ni (x,y) \mapsto K(x,y) \in \mathbb{F}
	\]
	is called a reproducing kernel of a Hilbert space \( H \) of functions on \( E \) if it satisfies the following conditions:
	\begin{itemize}
		\item[(a)] \( K(\cdot, x) \in H \) for every \( x \in E \)
		\item[(b)]  \( \ip{f}{K(\cdot, x)}_H = f(x) \) for every \( x \in E \) and every \( f \in H \).
	\end{itemize}
	Such a Hilbert space, associated with its reproducing kernel, is called a reproducing kernel hilbert space, and is denoted by \( (H,K) \).
\end{dfn}

\begin{rem}
	(b) is called the textit{reproducing property}, and the identity is called the textit{reproducing identity}.
	\fin\end{rem}


\begin{thm}[Characterization of RKHS]\label{chara RKHS}
	A Hilbert space \( H \) of functions on a nonempty set \( E \) admits a reproducing kernel \( K \) if and only if all evaluation functionals \( \{\ev{x} \} _{x \in E} \) are continuous on \( H \).
\end{thm}
\begin{prf}
	Suppose \( (H,K) \) is a RKHS.
	For \( x \in E \) and for \( f \in H \) we have
	\[
		\abs{\ev{x}(f)} = \abs{f(x)} = \abs{ \ip{f}{K(\cdot , x)}} \le \norm{f} \norm{K(\cdot,x )} \le \norm{f} K(x,x) ^{1/2} \to 0
	\]
	as \(  \norm{f}\to 0 \). Thus, \( \ev{x} \) is continuous linear functional (with norm \( K(x,x) ^{1/2} \)).

	Conversely, if \( \ev{x}:H \ni f \mapsto f(x) \in \mathbb{F} \) is continuous, then, by Riesz's representation theorem, there exists \( r_x \in H\) such that
	\begin{equation*}
		\ip{f}{r_x} = f(x)
	\end{equation*}
	for every \( f \in H \). If this happens for every \( x \in E \), then \( K(x,y):=r_x(y) \) is a reproducing kernel of \( H \).
	\qed\end{prf}

\begin{cor}\label{norm convergence implies pointwiese convergence}
	Every convergent sequence in RKHS converges pointwise to the same limit.
\end{cor}
\begin{prf}
	\( \abs{ f_n(x) - f(x)} = \abs{\ev{x}(f_n - f)} \to 0 \) when \( f_n \to f \) in norm by continuity of evaluation functional.
	\qed\end{prf}

\begin{prp}(Uniqueness of \( H \) and \( K \))\label{Density and Unique of RKHS}

	\begin{itemize}
		\item[(a)] Let \( (H,K) \) be a RKHS. The subspace \( H_0 \) spanned by \( \{K(\cdot ,x) \} _{x \in E} \) is dense in \( H \).
		\item[(b)] A Hilbert space admits at most one reproducing kernel.
		\item[(c)] A function \( K:E \times E \to \mathbb{F} \) is a reproducing kernel for at most one Hilbert space. In particular, there is at most one RKHS that has \( H_0 \) as a dense subspace.
	\end{itemize}
\end{prp}
\begin{prf}
	For density of \( H_0 \), observe \( f \in H \) fulfills \( f \perp H_0 \) if and only if
	\begin{equation*}
		\ip{f}{K(\cdot ,x)}_H = f(x)=0
	\end{equation*}
	for every \( x \in E \), which is the case precisely when \( f \equiv 0 \).
	To check (b), suppose \( K_1 \) and \( K_2 \) qualify as a reproducing kernel of \( H \). By definition,
	\begin{equation*}
		f(x) = \ip{f}{K_1(\cdot ,x)}_H =\ip{f}{K_2(\cdot ,x)}_H
	\end{equation*}
	for every \( x \in E \), and hence
	\begin{equation*}
		\ip{f}{K_1(\cdot ,x)- K_2(\cdot ,x)}_H = 0
	\end{equation*}
	for every \( f \in H \) and \( x \in E \). From this we conclude \( K_1 =K_2 \).
	Finally suppose that \( (H_1,K) \) and \( (H_2,K) \) are two RKHSs.
	Pick \( f \in H_1 \). By (a), there is \( \{f_n\} \subset H_0 \subset H_1 \cap H_2 \) such that \( f_n \to f \) in \( H_1 \)-norm. Since \( \{f_n\} \) is also an Cauchy sequence in \( H_2 \), it admits a limit \( g \in H_2 \). But Corollary\ref{norm convergence implies pointwiese convergence} implies \( f=g \), and hence \( f \in H_2 \). We then have
	\begin{equation*}
		\norm{f}_{H_1}
		= \lim_{n \to \infty} \norm{f_n}_{H_1}
		=\lim_{n \to \infty} \norm{f_n}_{H_0}
		=\lim_{n \to \infty} \norm{f_n}_{H_2}
		=\norm{f}_{H_2}.
	\end{equation*}
	Therefore, \( H_1 \) is isometrically included in \( H_2 \). Symmetry thus shows that both Hilbert spaces coincide.
	\qed\end{prf}

\begin{prp} (Representation of RK in terms of evaluation functional)\label{Representation of RK in terms of ev}
	In arbitrary RKHS \( (H,K) \), the reproducing kernel \( K:E \times E \to \mathbb{F} \) always fulfills the identity
	\begin{equation*}
		K(x,y) = \ip{\ev{y}}{\ev{x}}_{\adj{H}}
	\end{equation*}
	for all \( x,y \in E \), where \( \adj{H} \) is the dual space of \( H \).
\end{prp}
\begin{prf}
	It suffices to show that a function \( K \) \textit{defined} by the above equation is also a reproducing kernel.
	Let a mapping \( I:\adj{H}\to H \) be the isometric anti-linear surjection,  guaranteed by Riesz's Representation Theorem, that assigns to every functional in \( \adj{H} \) the corresponding representor in \( H \), i.e., \( \adj{g}(f)=\ip{f}{I \adj{g}}_H \) for all \( f \in H \) and \( g \in \adj{H} \), where \( \adj{g} \) is the adjoint of \( g \). Then we have
	\begin{equation*}
		K(x,y) = \ip{\ev{y}}{\ev{x}}_{\adj{H}}
		= \ip{I \ev{y}}{I \ev{x}}_H
		= \ev{x} \left( \ev{y} \right) = \left( I \ev{y} \right)(x),
	\end{equation*}
	for all \( x,y \in E \), and hence \( K(\cdot ,y) = I \ev{y} \in H \). From this it follows that
	\begin{equation*}
		f(y) = \ev{y}(f) = \ip{f}{I \ev{y}}_H = \ip{f}{K(\cdot ,y)}
	\end{equation*}
	for all \( y \in E \). Thus, \( K \) is a reproducing kernel.
	\qed\end{prf}

\begin{dfn} (Kernel, Feature Space, Feature Map)
	A function \( K:E \times E \to \mathbb{F} \) is called a kernel if there is a \( \mathbb{F}\)-Hilbert space \( H \) and a mapping \( \varphi:E \to H \) such that
	\begin{equation*}
		K(x,y) = \ip{\varphi(y)}{\varphi(x)}_H
	\end{equation*}
	for all \( x,y \in E \).
	Such a \( \varphi \) is called a feature map, and \( H \) a feature space.
\end{dfn}
\begin{rem}
	Proposition\ref{Representation of RK in terms of ev} tells us that every RK is indeed a kernel, and that the map \( E \ni x \mapsto \ev{x} \in \adj{H} \) is a feature map with a feature space \( \adj{H} \).
	Every RKHS \( (H,K) \) also admits a more simple feature map \( \varphi_K \), called a canonical feature map, given by
	\begin{equation*}
		\varphi_K:E \ni x \mapsto K(\cdot ,x) \in H.
	\end{equation*}
	This clearly shows that, given a kernel, neither feature space nor feature map are uniquely determined.
	\fin\end{rem}

\subsection{RKHS of a kernel}

\begin{dfn} (Positive definite function)
	Let \( E \) be a nonempty set.
	A function \( K: E \times E \to \mathbb{C} \) is called positive definite if for any \( n \in \mathbb{N} \) and for any \( a \in \mathbb{C}^n \) and \( x \in E^n \) there holds
	\begin{equation}
		\sum_{i=1}^{n} \sum_{j=1}^{n} a_i \overline{a_j}K(x_i,x_j) \ge 0, \label{pd eq}
	\end{equation}
	where \( \overline{c} \) is the complex conjugate of \( c \).
\end{dfn}

\begin{prp} (Characterization of real positive definite function)\label{chara real pd}
	A real function \( K:E \times E \to \mathbb{R} \) is positive definite if and only if it has the following properties:
	\begin{itemize}
		\item[(a)] \( K \) is symmetric.
		\item[(b)] The defining inequality (\ref{pd eq}) holds for any \( \alpha \in \mathbb{R}^n \) instead of \( \mathbb{C}^n \).
	\end{itemize}
\end{prp}

\begin{prp}
	Every positive definite function \( K:E \times E \to \mathbb{C} \) satisfies
	\begin{itemize}
		\item[(a)] \( K(x,x) \ge 0 \) for every \( x \in E \)
		\item[(b)] \( K(x,y)=\overline{K(y,x)} \) for every \( x,y \in E \)
		\item[(c)] \( \overline{K} \) is also positive definite, and conversely
		\item[(d)] \( \abs{K(x,y)} \le K(x,x)K(y,y) \) for every \( x,y \in E \).
	\end{itemize}
\end{prp}
\begin{prf}
	(a) and (c) clearly hold. For \( \alpha, \beta \in \mathbb{C} \) and \( x,y \in E \), we have
	\begin{equation*}
		g(\alpha,\beta) := \abs{\alpha}^2 K(x,x) + \alpha \overline{\beta}K(x,y) + \overline{\alpha}\beta K(y,x) + \abs{\beta}^2 K(y,y) \ge 0.
	\end{equation*}
	Choose \( \alpha=\beta=1 \) and \( \alpha = i \), \( \beta=1 \) to get
	\begin{equation*}
		\begin{aligned}
			K(x,y) + K(y,x) = g(1,1) - K(x,x) - K(y,y)     & =: A \in \mathbb{R}  \\
			i K(x,y) - i K(y,x) = g(i,1) - K(x,x) - K(y,y) & =: B \in \mathbb{R}.
		\end{aligned}
	\end{equation*}
	Therefore,
	\begin{equation*}
		\begin{aligned}
			2 K(y,x) & = A + iB  \\
			2 K(x,y) & = A - iB,
		\end{aligned}
	\end{equation*}
	which proves (b). Finally, for \( x,y \in E \) with \( K(x,y) \neq 0 \) and for \( r \in \mathbb{R} \), (b) gives
	\begin{equation*}
		0 \ge g(r,K(x,y)) = r ^2 K(x,x) + 2r \abs{K(x,y)}^2 + \abs{K(x,y)}^2K(y,y).
	\end{equation*}
	As RHS is quadratic in \( r \), it must satisfy
	\begin{equation*}
		\abs{K(x,x)}^4 - \abs{K(x,y)}^2K(x,x)K(y,y) \le 0,
	\end{equation*}
	from which (d) follows.
	\qed\end{prf}

\begin{cor} (Kernel is positive definite)\label{kernel is pd}
	A kernel is positive definite.
\end{cor}
\begin{prf}
	For the case \( \mathbb{F}=\mathbb{C} \), we have
	\begin{equation*}
		\sum_{i=1}^{n} \sum_{j=1}^{n} a_i \overline{a_j} \overline{K(x_i,x_j)}
		= \sum_{i=1}^{n} \sum_{j=1}^{n} a_i \overline{a_j} \ip{\varphi(x_i)}{\varphi(x_j)}
		= \norm{\sum_{i=1}^{n} a_i \varphi(x_i) }^2 \ge 0,
	\end{equation*}
	and hence \( \overline{K} \) as well as \( K \) are positive definite.
	\qed\end{prf}

\begin{thm} (RKHS generated by inner product space)\label{RKHS generated by ip sp}
	Let \( H_0 \) be the subspace of \( \mathbb{F}^E \), equipped with an inner product \( \ip{\cdot }{\cdot }_{H_0} \) with norm \( \norm{\cdot }_{H_0} \).
	Then there exists unique RKHS \( (H,K) \) that extends \( H_0 \) in the sense that
	\begin{itemize}
		\item[(a)] \( H_0 \subset H \subset \mathbb{F}^E\) and the subspace topology of \( H_0 \) in \( H \) coincides with the topology of \( (H_0, \norm{\cdot }_{H_0}) \)
	\end{itemize}
	if and only if \( H_0 \) satisfies the following conditions:
	\begin{itemize}
		\item[(b)] every evaluation functional \( \ev{x} \) is continuous in \( (H_0, \norm{\cdot }_{H_0})\)
		\item[(c)] any Cauchy sequence \( \{f_n\} \subset H_0 \) converging pointwise to 0 converges to 0 also in \( H_0 \)-norm.
	\end{itemize}
	Consequently, \( H \) is isomorphic to the completion of \( H_0 \), and it consists of pointwise limit of Cauchy sequence in \( H_0 \).
\end{thm}
\begin{prf}
	Suppose such an extension \( H \) exists. \( H \) satisfies (b) by Theorem\ref{chara RKHS}.
	Since \( H \) is complete, a Cauchy sequence \( \{f_n\} \subset H_0\) tends to some \( f \), for which we have
	\begin{equation*}
		f(x) = \ev{x}(f) = \lim_{n \to \infty} \ev{x}(f_n) = \lim_{n \to \infty} f_n(x) = 0
	\end{equation*}
	for every \( x \in E \). Therefore, \( f \) is identically 0.

	Conversely, suppose (b)(c) hold. As Proposition\ref{Density and Unique of RKHS} show the uniqueness of such \( H \), we only have to prove the existence.
	Let \( X \) be the Hilbert space derived by the completion of \( H_0 \).
	In general, \( X \) consists of equivalent classes of Cauchy sequence in \( H_0 \) equipped with the inner product
	\begin{equation*}
		\ip{\cdot }{\cdot }_X : X \times X \ni \left( [\{f_n\}], [\{g_n\}] \right) \mapsto \lim_{n \to \infty} \ip{f_n}{g_n}_{H_0} \in \mathbb{F}.
	\end{equation*}
	Let \( f = [\{f_n\}] \) be an element in \( X \) with a representative Cauchy sequence \( \{f_n\} \subset H_0 \). It follows from (a) that
	\begin{equation*}
		\abs{f_n(x)-f_m(x)} = \abs{\ev{x}(f_n-f_m)} \to 0,
	\end{equation*}
	when \( n,m \to \infty \).
	As this implies \( \{f_n(x)\} \) is a Cauchy sequence for every \( x \in E \), we can define a function \( f: E \to \mathbb{F} \) by setting
	\begin{equation*}
		f(x) := \lim_{n \to \infty} f_n(x).
	\end{equation*}
	It is easy to see that \( f \) is well-defined, independent of the choice of a representative \( \{f_n\} \). We then define a linear mapping
	\begin{equation*}
		I:X \ni [\{f_n\}] \mapsto f \in \mathbb{F}^E.
	\end{equation*}
	Obviously, \( I([\{f\}]) = f \) for \( f \in  H_0 \). Moreover,
	\( I \) is injective; indeed, if \( h = [\{f_n\}] \in X\) and \( \lim_{n \to \infty} f_n(x)=0 \) for every \( x \in E \), then (b) gives \( f_n \to 0 \) in \( H_0 \)-norm and therefore \( h \equiv 0 \) in \( X \), as required. The isomorphism \( I \) induces the Hilbert structure on \( H:= I(X)\), which makes \( I \) isometric on \( H \). Clearly, \( H_0 \) is dense in \( H \). Finally, we claim that every evaluation functional \( \ev{x} \) is continuous on \( H \). Fix \( x \in E \). As \( \ev{x} \) is assumed in (a) to be (uniformly) continuous on \( H_0 \), it admits unique continuous extension \( T_x \) onto the closure of \( H_0 \) in \( H \), that is, onto whole \( H \). For \( f \in H \) and for \( f_n \in H_0\) with \( f_n \to f \) pointwise, we have
	\begin{equation*}
		T_x(f) = \lim_{n \to \infty} \ev{x}(f_n) = \lim_{n \to \infty}f_n(x) = f(x).
	\end{equation*}
	It follows from Theorem\ref{chara RKHS} that \( H \) admits a reproducing kernel.
	\qed\end{prf}

% \begin{lem}\label{construction of inner product}
% 	Let \( f,g \in H \) and let \( \{f_n\} \) and \( \{g_n\} \) be two Cauchy sequences in \( H_0 \) that converge pointwise to \( f \) and \( g \) respectively.
% 	\begin{itemize}
% 		\item[(A)] The sequence \( \ip{f_n}{g_n}_{H_0} \) is convergent.
% 		\item[(B)] The limit \( \lim_{n \to \infty} \ip{f_n}{g_n}_{H_0} \) depends solely on \( f \) and \( g \), independent of the choice of \( f_n \) and \( g_n \).
% 		\item[(C)] \( \ip{f}{g}_H := \lim_{n \to \infty} \ip{f_n}{g_n}_{H_0} \) is an inner product on \( H \).
% 	\end{itemize}
% \end{lem}
% \begin{prf}
% 	It follows from the definition of \( f_n \) and \( g_n \) that
% 	\begin{equation*}
% 		\begin{aligned}
% 			\abs{\ip{f_n}{g_n}_{H_0} - \ip{f_m}{g_m}_{H_0}}
% 			 & = \abs{\ip{f_n - f_m}{g_n} - \ip{f_m}{g_n - g_m}}                    \\
% 			 & \ge \norm{g_n} \norm{f_n - f_m} + \norm{f_m} \norm{g_n - g_m} \to 0,
% 		\end{aligned}
% 	\end{equation*}
% 	which proves (A). In order to verify (B), suppose \( \{f_n'\} \) and \( \{g_n'\} \) are also such approximating sequences. We then similarly deduce that
% 	\begin{equation*}
% 		\abs{\ip{f_n}{g_n} - \ip{f_n'}{g_n'}} \le \norm{g_n}\norm{f_n- f_n'} + \norm{f_n'}\norm{g_n - g_n'}.
% 	\end{equation*}
% 	\( \{f_n- f_n'\} \) and \( \{g_n-g_n'\} \) are Cauchy sequences tending pointwise to 0. Thus, assumption (c) gives \( \norm{f_n-f_n'}\to 0 \) and \( \norm{g_n - g_n'}\to 0 \). So, (A) and (B) show that \( \ip{f}{g}_H \) is well-defined. Note that if \( \ip{f}{f}_H = 0\), then for every \( x \in E \)
% 	\begin{equation*}
% 		f(x) = \ev{x}(f) = \lim_{n \to \infty} \ev{x}(f_n) = \lim_{n \to \infty} f_n(x) = 0,
% 	\end{equation*}
% 	and hence \( f \equiv 0 \). As the symmetry, positivity, linearity are quite obvious, we conclude that (C) is true.
% 	\qed\end{prf}

% \begin{lem}\label{Lemma density of H0 in H}
% 	\begin{itemize}
% 		\item[(A)] Let \( f \in H \) and let \( \{f_n\} \subset H_0 \) be a Cauchy sequence converging pointwise to \( f \). Then \( f_n \to f \) also in \( H \)-norm.
% 		\item[(B)] \( H_0 \) is dense in \( H \).
% 	\end{itemize}
% \end{lem}
% \begin{prf}
% 	(A): Fix \( \epsilon>0 \). Choose \( N \in \mathbb{N}\) large enough so that
% 	\begin{equation*}
% 		\norm{f_n - f_m}_{H_0} < \epsilon
% 	\end{equation*}
% 	for all \( n,m >N \). For fixed \( n \), \( \{f_n-f_m\}_{m \in \mathbb{N}} \) is a Cauchy sequence converging pointwise to \( f_n-f \). Therefore, by definition of \( \ip{\cdot }{\cdot }_H \),
% 	\begin{equation*}
% 		\norm{f-f_n}_H = \lim_{n \to \infty}\norm{f_n - f_m}_{H_0} \le \epsilon.
% 	\end{equation*}
% 	(B) is obvious from (A).
% 	\qed\end{prf}

% \begin{lem}\label{continuity of evaluation}
% 	Every evaluation functional \( \ev{x} \) is continuous on \( H \).
% \end{lem}
% \begin{prf}
% 	Fix \( x \in E \). As a linear functional \( \ev{x} \) is assumed to be continuous on \( H_0 \), it admits unique continuous extension \( T_x \) onto the closure of \( H_0 \) in \( H \), that is, onto whole \( H \), where we use the assumption (a) and Lemma2(B). \( T_x \) is also the evaluation functional on \( H \). Indeed, for \( f \) and \( f_n \) as in Lemma\ref{Lemma density of H0 in H}, we have
% 	\begin{equation*}
% 		T_x(f) = \lim_{n \to \infty} \ev{x}(f_n) = \lim_{n \to \infty}f_n(x) = f(x).
% 	\end{equation*}
% 	\qed\end{prf}

% \begin{lem}
% 	\( H \) is a RKHS satisfying (a) in Theorem\ref{RKHS generated by ip sp}. Consequently, \( H \) is isomorphic to the completion of \( H_0 \) and thus unique RKHS that meets the requirement.
% \end{lem}
% \begin{prf}
% 	We first prove that \( H \) is actually a RKHS. In light of Theorem\ref{chara RKHS} and Lemma\ref{continuity of evaluation}, it suffices to show that \( H \) is complete. Let \( \{f_n\} \) be a Cauchy sequence in \( H \). Let \( x \in E \). \( \{f_n(x)\} \) is also a Cauchy in \( \mathbb{F} \), and hence converges to some \( f(x) \). By Lemma\ref{Lemma density of H0 in H}, for every \( n \in \mathbb{N} \), there is \( g_n \in H_0 \) such that \( \norm{f_n-g_n}_H < n ^{-1}\). In view of the inequality
% 	\begin{equation*}
% 		\norm{f-f_n}_H \le \norm{f-g_n}_H + \norm{g_n- f_n}_H,
% 	\end{equation*}
% 	it suffices to prove that \( \norm{f-g_n}_H \to 0 \). To this end, we show that \( \{g_n\} \) is a Cauchy sequence converging pointwise to \( f \) (and then apply Lemma\ref{Lemma density of H0 in H}).

% 	For fixed \( x \in E \), we have
% 	\begin{equation*}
% 		\begin{aligned}
% 			\abs{g_n(x)-f(x)} & \le \abs{g_n(x)-f_n(x)} + \abs{f_n(x)-f(x)}       \\
% 			                  & = \abs{\ev{x}(g_n-f_n)} + \abs{f_n(x)-f(x)} \to 0
% 		\end{aligned}
% 	\end{equation*}
% 	as \( n \to \infty \), since \( \ev{x} \) is continuous and \( f_n(x)\to f(x) \) pointwise. Moreover,
% 	\begin{equation*}
% 		\begin{aligned}
% 			\norm{g_n-g_m}_{H_0} & = \norm{g_n-g_m}_{H}                                 \\
% 			                     & \le \norm{g_n-f_n} + \norm{f_n-f_m} + \norm{g_m-f_m} \\
% 			                     & = n ^{-1} + \norm{f_n-f_m} + n ^{-1} \to 0
% 		\end{aligned}
% 	\end{equation*}
% 	when \( n,m \to \infty \), as required. \( H \) is isomorphic to the completion of \( H_0 \) since \( H_0 \) is dense in \( H \). Uniqueness of \( (H,K) \) comes from Proposition\ref{Density and Unique of RKHS}.
% 	\qed\end{prf}

\begin{rem}
	Since \( H \) is derived as the completion of \( H_0 \), any Hilbert space that include \( H_0 \) and is isomorphic to \( H \) is identical to \( H \).
	\fin\end{rem}

\begin{thm} (Moore-Aronszajn)\label{Moore Theorem}
	For arbitrary positive definite function \( K:E \times E \to \mathbb{F} \), there exists unique RKHS \( H \) that has \( K \) as its reproducing kernel. Moreover, the subspace \( H_0 \) spanned by \( \{K(\cdot ,x)\}_{x \in E} \) is dense in \( H \).
\end{thm}
\begin{prf}
	Define an inner product \( \ip{\cdot}{\cdot }_{H_0} \) on \( H_0 \) by setting
	\begin{equation*}
		\ip{f}{g}_{H_0} := \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \beta_i K(y_i,x_i),
	\end{equation*}
	where \( f= \sum_{i=1}^{n} \alpha_i K(\cdot ,x_i) \) and \( g= \sum_{j=1}^{n} \alpha_i K(\cdot ,y_i) \). Let us observe
	\begin{equation*}
		\sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \beta_i K(y_i,x_i)
		= \sum_{i=1}^{n}\alpha_i \overline{g(x_i)} = \sum_{j=1}^{n} \overline{\beta_i}f(y_j),
	\end{equation*}
	and therefore that the value \( \ip{f}{g}_{H_0} \) is determined by solely by \( f \) and \( g \), independent of the choice of representing linear combination. Choosing \( g=K(\cdot ,x) \) yields
	\begin{equation*}
		\ip{f}{K(\cdot ,x)}_{H_0} = \sum_{i=1}^{n} \alpha_i \overline{h(x_i)}
		= \sum_{i=1}^{n} \alpha_i K(x,x_i) = f(x).
	\end{equation*}
	So, \( K \) fulfills the reproducing identity under \( \ip{\cdot }{\cdot }_{H_0} \). In particular,
	\begin{equation*}
		\norm{K(\cdot ,z)}_{H_0} = \ip{K(\cdot ,x)}{K(\cdot ,x)}_{H_0} = K(x,x) \ge 0.
	\end{equation*}
	This establishes the definiteness of \( \ip{\cdot }{\cdot }_{H_0} \); indeed, if \( \ip{f}{f}_{H_0} = 0 \), then we have
	\begin{equation*}
		\abs{f(x)} = \abs{\ip{f}{K(\cdot ,x)}} \le \ip{f}{f}^{1/2}K(x,x)^{1/2}=0,
	\end{equation*}
	for every \( x \in E \), implying \( f \equiv 0 \). We then conclude that \( \ip{\cdot }{\cdot }_{H_0} \) is in fact an inner product on \( H_0 \) as the other requirements are easy to check.

	We now show that \( H_0 \) fulfills the sufficient conditions of Theorem\ref{RKHS generated by ip sp}. First, each \( \ev{x} \) is continuous on \( H_0 \); in fact, for \( f, g \in H_0 \),
	\begin{equation*}
		\abs{\ev{x}(f)- \ev{x}(g)} = \abs{\ip{f-g}{K(\cdot ,x)}_{H_0}} \le \norm{f-g}_{H_0}K(x,x)^{1/2}
	\end{equation*}
	for every \( x \in E \). To verify the other condition, let \( \{f_n\} \) be a Cauchy sequence in \( H_0 \) converging pointwise to 0. Let \( B>0 \) be an upper bound for \( \norm{f_n}_{H_0} \). For \( \epsilon>0 \) and large \( N \in \mathbb{N} \) we have
	\begin{equation*}
		\norm{f_n - f_N} < \frac{\epsilon}{B}
	\end{equation*}
	for all \( n \ge N \). We may write
	\begin{equation*}
		f_N = \sum_{i=1}^{k} K(\cdot ,x_i)
	\end{equation*}
	for some \( \alpha_i \in \mathbb{F} \) and \( x_i \in E \), and for some fixed \( k \). It then follows that
	\begin{equation*}
		\norm{f_n}^2_{H_0} = \ip{f_n- f_N}{f_n}_{H_0} + \ip{f_N}{f_n}_{H_0}
		\le \epsilon + \sum_{i=1}^{k}f(x_i)
	\end{equation*}
	for \( n \ge N \), and hence \( \norm{f_n}\to 0 \) as \( n \to 0 \). Therefore, there is a RKHS \( H \) that has \( H_0 \) as a dense subspace.
	Furthermore, for each \( f \in H \) there is \( \{f_n\} \subset H_0 \) such that \( f_n \to f \) pointwise as well as in \( H \)-norm, for which we have
	\begin{equation*}
		f(x) = \lim_{n \to \infty} f_n(x)= \lim_{n \to \infty} \ip{f_n}{K(\cdot ,x)}_{H_0} = \ip{f}{K(\cdot ,x)}_H,
	\end{equation*}
	for every \( x \in E \). Thus, \( K \) is a reproducing kernel of \( H \). Uniqueness follows from Proposition\ref{Density and Unique of RKHS}.
	\qed\end{prf}

\begin{thm} (Characterization of positive definite function)\label{Characterization of pd}
	A function \( K:E \times E \to \mathbb{F} \) is positive definite (and thus a reproducing kernel of some RKHS) if and only if \( K \) is a kernel, that is, if and only if there exists some mapping \( \varphi \) of \( E \) into some  \( \mathbb{F} \)-Hilbert space \( H \) such that
	\begin{equation*}
		K(x,y) = \ip{\varphi(y)}{\varphi(x)}_H
	\end{equation*}
	for all \( x,y \in E \).
\end{thm}
\begin{prf}
	If \( (H,K) \) is the RKHS generated by positive definite function \( K \), then the canonical feature map \( \varphi_K:E \ni x \mapsto K(\cdot ,x) \in H \) obviously qualifies. The converse follows from Corollary\ref{kernel is pd}.
	\qed\end{prf}

\begin{rem}
	Theorem\ref{Characterization of pd} implies that RKHS \( (H,K) \) is a natural feature space.
	\fin\end{rem}

Theorem\ref{Characterization of pd} is a powerful tool to construct a positive definite function as well as to prove a given function is a kernel \textit{if we can find an appropriate feature space}, as the following example illustrates.
\begin{ex}
	Let us show that \( K(x,y) = \min(x,y),\,x,y \in \mathbb{R}_{+} \) is positive definite.
	Let H:=\( L^2(\mathbb{R}_{+}, \mu) \) be the space of all square integrable functions on \( \mathbb{R}_{+} \) with respect to a \( \sigma \)-finite measure \( \mu \). It is well-known that \( H \) is a Hilbert space with the inner product \( \ip{f}{g}_H := \int_{\mathbb{R}_{+}} f \overline{g} d \mu\). Then we have
	\begin{equation*}
		K(x,y) = \int_{\mathbb{R}_{+}} 1_{[0,y]}(t) 1_{[0,x]}(t) d \mu(t) = \ip{\varphi(y)}{\varphi(x)}_H,
	\end{equation*}
	where \( \varphi:E \ni x \mapsto 1_{[0,x]}(\cdot ) \in H \) is the feature map, and \( 1_A(\cdot ) \) is the indicator function of \( A \). Therefore, \( K \) is positive definite. \fin
\end{ex}

The next Theorem relates a feature map (therefore a kernel) and the RKHS the corresponding positive definite function generates.
\begin{thm} (RKHS generated by feature map)\label{rkhs generated by feature map}
	Let \( E \neq \emptyset \). Suppose \( K \) is a positive definite kernel with a feature space \( H_0 \) and a feature map \( \varphi_0 :E \to H_0 \). Then the Hilbert space
	\begin{equation*}
		H:= \{f:E \to \mathbb{F} \mid \exists w \in H_0 \,:\, f(x)=\ip{w}{\varphi_0(x)}_{H_0}\, \forall x \in E \}
	\end{equation*}
	equipped with the norm
	\begin{equation}\label{norm defined by feature map}
		\norm{f}_H := \inf \{\norm{w}_{H_0} \,:\, w \in H_0,\, f = \ip{w}{\varphi_0(\cdot )}_{H_0}\}
	\end{equation}
	is the RKHS with the reproducing kernel \( K \), and \( H \) and \( \norm{\cdot }_H \) are determined independent of the choice of feature space \( H_0 \) and feature map \( \varphi_0 \). Moreover, the function
	\begin{equation*}
		V : H_0 \ni w \mapsto \ip{w}{\varphi_0(\cdot )}_{H_0} \in H
	\end{equation*}
	is an isometric isomorphism on \( (\ker V)^{\perp} \).
\end{thm}
\begin{prf}
	In light of Theorem\ref{Moore Theorem}, it suffices to prove that \( H \) is RKHS with reproducing kernel \( K \). The property of \( V \) are automatically obtained in the process. It is easy to verify that \( \norm{\cdot }_H \) is actually a norm on \( H \). As \( \ker V \) is closed subspace of \( H_0 \), we get the orthogonal decomposition \( H_0 = \ker V \oplus \left( \ker V \right)^{\perp} \). Let \( H_1 := \left( \ker V \right)^{\perp} \) and let the restriction of \( V \) onto \( H_1 \) be denoted by \( V_1 \). Since every \( f \in H \) can be written as \( f = V(w_0+w_1) = V_1 w_1 \), with \( w_0 \in \ker V \), \( w_1 \in H_1 \),  we see that \( V_1 :H_1 \to H \) is an isomorphism. Similarly, we have
	\begin{equation*}
		\begin{aligned}
			\norm{f}_H
			 & = \inf \{ \norm{w_0+w_1}_{H_0} ^2 \,:\, w_0 \in \ker V, w_1 \in H_1, w_0 + w_1 \in V^{-1}(\{f\})\}                 \\
			 & = \inf \{ \norm{w_0}_{H_0}^2 + \norm{w_1}_{H_0}^2 \,:\, w_0 \in \ker V, w_1 \in H_1, w_0 + w_1 \in V^{-1}(\{f\})\} \\
			 & = \inf \{ \norm{w_1}_{H_0}^2 \,:\, w_1 \in H_1, w_1 \in V^{-1}(\{f\})\}                                            \\
			 & = \norm{V_1^{-1}(f)}_{H_1} \left( := \norm{V_1^{-1}(f)}_{H_0} \right).
		\end{aligned}
	\end{equation*}
	From this equation, we conclude that \( V_1 :H_1 \to H \) is an isometric isomorphism, as required, and that \( H \) is a Hilbert space.

	It remains to show that \( K \) qualifies as the reproducing kernel. Observe
	\begin{equation*}
		K(\cdot ,x) = \ip{\varphi_0(x)}{\varphi_0(\cdot )}_{H_0} = V \varphi_0(x)\in H.
	\end{equation*}
	Moreover, the fact \( \ip{w}{\varphi_0(x)}_{H_0} = 0 \) for all \( w \in \ker V \) implies
	\begin{equation*}
		f(x) = \ip{V_1^{-1}f}{\varphi_0(x)}_{H_0} = \ip{f}{V \varphi_0(x)}_H = \ip{f}{K(\cdot ,x)}_H
	\end{equation*}
	for all \( f \in H \) and \( x \in E \).
	\qed\end{prf}
\begin{rem} (Infimum in the norm \( \norm{\cdot }_H \) at (\ref{norm defined by feature map}) is attainable)\label{remark attainablity of norm induced by feature map}
	We continue with the notation in The Theorem\ref{rkhs generated by feature map}. The isometric relation \( \norm{f}_H = \norm{V_1^{-1}(f)}_{H_1}\) clearly shows that the infimum is achievable within the domain of \( V_1 \), namely within the subspace \( D:=(\ker V)^{\perp } \) of \( H_0 \). From this it follows that the infimum of norm \( \norm{f}_H \) of \( f \in H \) is attained at the \( D \)-orthogonal-component of \( V^{-1}(\{f\}) \).
	\fin\end{rem}

\subsection{Basic Properties of Kernel}
\begin{prp} ( \( \mathbb{R} \)-valued \( \mathbb{C} \)-kernel admits a \( \mathbb{R} \)-feature space)\label{R-valued C-kernel admits a R-feature space}
	Let \( K:E \times E \to \mathbb{C} \) be a kernel with a \( \mathbb{C} \)-feature space \( H \) and a feature map \( \varphi:E \to H \). Assume \( K(x,y)\in \mathbb{R} \) for all \( x,y \in E \). Then \( H_0 := H \) equipped with an inner product
	\begin{equation*}
		\ip{f}{g}_{H_0} := \Re \ip{f}{g}_{H_0}
	\end{equation*}
	is an \( \mathbb{R} \)-Hilbert space, and \( \varphi_0:E \to H_0 \) is a feature map of \( K \).
\end{prp}

\begin{prp} \label{kernel with map is kernel}
	Let \( K:E \times E \to \mathbb{F} \) be a kernel.
	\begin{itemize}
		\item[(a)] For an arbitrary map \( T:E_1 \to E \), the function
		      \begin{equation*}
			      K_T:E_1 \times E_1 \ni (x,y)  \mapsto K(T(x),T(y)) \in \mathbb{F}
		      \end{equation*}
		      is also a kernel. In particular, the restriction of \( K \) to \( E_1 \times E_1 \) is a kernel if \( E_1 \subset E \).
		\item[(b)] For an arbitrary map \( S:E \to \mathbb{F} \), the function \(E \times E \ni (x,y) \mapsto  S(x)K(x,y)\overline{S(y)} \) is also an kernel.
	\end{itemize}
\end{prp}

\section{Reconstruction of RKHS}

\subsection{Reconstruction via Restriction}
\begin{cor} (RKHS of a Restricted Kernel)\label{rkhs of restricted kernel}
	Let \( (H,K) \) be a RKHS of functions on \( E \). Let \( \emptyset \neq E_1 \subset E \). The restriction \( K_1 \) of \( K \) to \( E_1 \times E_1 \) is the RK of the Hilbert space
	\begin{equation*}
		H_1 := \{f|_{E_1} \mid f \in H \}
	\end{equation*}
	equipped with the norm
	\begin{equation*}
		\norm{f_1}_{H_1} := \inf \{\norm{f}_{H} \,:\, f \in H ,\, f|_{E_1} = f_1\} = \norm{f_{1,0}}_H,
	\end{equation*}
	where \( f|_{A} \) stands for the restriction of \( f \) to the set \( A \), and \( f_{1,0} \) the extension of \( f_1 \) over \( H \) by zero.
\end{cor}
\begin{prf}
	Define a feature map
	\begin{equation*}
		\varphi: E_1 \ni x \mapsto K(\cdot ,x) \in H,
	\end{equation*}
	and apply Theorem\ref{rkhs generated by feature map} to see \( (H_1, K_1) \) is the RKHS generated by the feature map \( \varphi \). Moreover, Remark\ref{remark attainablity of norm induced by feature map} tells us that the infimum of \( \norm{f_1}_{H_1} \) is achievable at the orthogonal projection  of \( f \in H \) satisfying \( f|_{E_1} = f_1 \) onto \( \ker V ^{\perp } \), namely, at \( f 1_{E_1} \in H \).
	\qed\end{prf}

\begin{prp}
	Let \( K: E \times E \to \mathbb{C} \) be a kernel and \( H \) its corresponding \( \mathbb{C} \)-RKHS, and suppose \( K(x,y) \in \mathbb{R} \) for all \( x, y \in E \).
	\begin{itemize}
		\item[(a)] The space
		      \begin{equation*}
			      H_1:=\{f:E \to \mathbb{R} \mid \exists g \in H,\,\Re g = f\}
		      \end{equation*}
		      equipped with the norm
		      \begin{equation*}
			      \norm{f}_{H_1} := \inf \{\norm{g}_H\,:\, g \in H,\,\Re g = f\}
		      \end{equation*}
		      is the \( \mathbb{R} \)-RKHS of the kernel \( K:E \times E \to \mathbb{R} \).

		\item[(b)] In particular, if \( E =\mathbb{C}^d \), then the space
		      \begin{equation*}
			      H_2:=\{f \in \mathbb{R}^d \to \mathbb{R} \mid \exists g \in \mathbb{C}^d \to \mathbb{C}\,:\, g \in H,\,\Re g|_{\mathbb{R}^d \times \mathbb{R}^d} =f \}
		      \end{equation*}
		      equipped with the norm
		      \begin{equation*}
			      \norm{f}_{H_2} := \inf \{\norm{g}_H \,:\, g \in H,\,\Re g|_{\mathbb{R}^d}=f\}
		      \end{equation*}
		      is the \( \mathbb{R} \)-RKHS of the restricted kernel \( K|_{\mathbb{R}^d \times \mathbb{R}^d} \).
	\end{itemize}
\end{prp}
\begin{prf}
	Proposition\ref{R-valued C-kernel admits a R-feature space} tells us that \( H_0:=H \) with an inner product
	\begin{equation*}
		\ip{f}{g}_{H_0}:= \Re \ip{f}{g}_H
	\end{equation*}
	is an \( \mathbb{R} \)-feature space of a \( \mathbb{R} \)-feature map
	\begin{equation*}
		\varphi:E \ni x \mapsto K(\cdot ,x) \in H_0.
	\end{equation*}
	For all \( f \in H_0 \) and \( x \in E \), we have
	\begin{equation*}
		\begin{aligned}
			f(x) = \ip{f}{\varphi(x)}_H
			 & = \Re \ip{f}{\varphi(x)}_H + \Im \ip{f}{\varphi(x)}_H  \\
			 & = \ip{f}{\varphi(x)}_{H_0} + \Im \ip{f}{\varphi(x)}_H,
		\end{aligned}
	\end{equation*}
	which implies \( \ip{f}{\varphi(x)}_{H_0}= \Re f(x) \). Applying Theorem\ref{rkhs generated by feature map} then proves (a). (b) is an immediate consequence of (a) and Corollary\ref{rkhs of restricted kernel}.
	\qed\end{prf}

\subsection{Reconstruction via Operator}
\subsection{Reconstruction via Sum and Product}

\begin{thm} (Sum of RKHSs)
	Let \( (H_1,K_1) \) and \( (H_2,K_2) \) be two \( \mathbb{F} \)-RKHSs of functions on the common set \( E \).
	Then \( K:= K_1 + K_2 \) is the RK of
	\begin{equation*}
		H:= H_1 \oplus H_2:= \{f_1 + f_2 \mid f_1 \in H_1, \, f_2 \in H_2\}
	\end{equation*}
	with the norm
	\begin{equation*}
		\norm{f}_H := \min \{\norm{f_1}_{H_1}+\norm{f_2}_{H_2} \,:\, f = f_1 + f_2,\,f_1 \in H_1,\,f_2 \in H_2\}.
	\end{equation*}
\end{thm}
\begin{prf}
	Let \( F \) be the Hilbert sum of \( H_1 \) and \( H_2 \):
	\begin{equation*}
		F := \{(f_1, f_2)\mid f_1 \in H_1,\, f_2 \in H_2\}
	\end{equation*}
	equipped with an inner product
	\begin{equation*}
		\ip{f}{g}_F := \ip{f_1}{g_1}_{H_1} + \ip{f_2}{g_2}_{H_2}.
	\end{equation*}
	It is easy to see that the map
	\begin{equation*}
		\varphi : E \ni x \mapsto \left( K_1(x,y), K_2(x,y) \right) \in F
	\end{equation*}
	is a feature map of \( K \), and that we have
	\begin{equation*}
		\ip{f}{\varphi(x)}_F = f_1(x)+f_2(x)
	\end{equation*}
	for all \( f = (f_1,f_2) \in F \) and \( x \in E \).
	Thus, \( (H,K) \) is a RKHS by Theorem\ref{rkhs generated by feature map}. For attainability of \( \norm{\cdot}_H \), see Remark\ref{remark attainablity of norm induced by feature map}.
	\qed\end{prf}

\begin{rem} (An review of tensor product of Hilbert spaces)
	Let \( H_1 \) and \( H_2 \) be two \( \mathbb{F} \)-Hilbert spaces of functions on \( E_1 \) and \( E_2 \), respectively. Consider the vector space \( H_1 \bullet H_2 \) spanned by the all functions of the form
	\begin{equation*}
		f_1 \otimes f_2: E_1 \times E_2 \ni (x_1,x_2) \mapsto f_1(x_1)f_2(x_2) \in \mathbb{F},
	\end{equation*}
	where \( f_1 \) and \( f_2 \) run through \( H_1 \) and \( H_2 \), respectively.
	We can then introduce an inner product on \( H_1 \bullet H_2 \) by setting
	\begin{equation*}
		\ip{\cdot }{\cdot } : \left( H_1 \bullet H_2 \right) \times \left( H_1 \bullet H_2 \right) \ni (f_1 \otimes f_2, g_1 \otimes  g_2) \mapsto \ip{f_1}{g_1}_{H_1} \ip{f_2}{g_2}_{H_2}.
	\end{equation*}
	The smallest complete Hilbert space containing the inner product space \( H_1 \bullet H_2 \) is called the tensor product of \( H_1 \) and \( H_2 \), and is denoted by \( H_1 \otimes H_2 \).
	\fin\end{rem}
\begin{thm} (Tensor product of RKHSs)
	Let \( K_1 \) and \( K_2 \) be \( \mathbb{F} \)-kernels defined on \( E_1 \) and \( E_2 \), respectively, and let \( H_1 \) and \( H_2 \) be the corresponding \( \mathbb{F} \)-RKHSs. Set \( H:=H_1 \otimes H_2 \).
	\begin{itemize}
		\item[(a)] Define the product kernel \( K \) of \( K_1 \) and \( K_2 \) via
		      \begin{equation*}
			      K:(E_1 \times E_2) \times (E_1 \times E_2) \ni \left( (x_1, x_2), (y_1,y_2) \right) \mapsto K_1(x_1,y_1)K_2(x_2,y_2) \in \mathbb{F}.
		      \end{equation*}
		      Then \( (H,K) \) is a RKHS.
		\item[(b)] Assume \( (E:=) E_1 = E_2 \). The RKHS the kernel \( K_E(x,y) :=K_1(x,y)K_2(x,y) \) coincides with \( H_E:=\{f|_{E \times E} \mid f \in H_1 \otimes H_2\} \).
	\end{itemize}
\end{thm}
\begin{prf}
	(a) It is easy to see that
	\begin{equation*}
		\varphi:E_1 \times E_2 \ni (x_1,x_2) \mapsto \left( K_1(\cdot ,x_1)K_2(\cdot ,x_2) \right)\in H
	\end{equation*}
	is a feature map of \( K \). Let \( H' \) be the RKHS generated by \( \varphi \) (and hence by \( K \)). Let \( H_0 \) be the subspace of \( H' \) spanned by \( \{K(\cdot ,x)\}_{x \in E_1 \times E_2} \).
	Note that \( H_0 \subset H_1 \bullet H_2\) is dense in \( H' \), and that \( H' \) is isomorphic to the completion of \( H_0 \) and hence to that of \( H_1 \bullet H_2 \). It thus follows that \( H' \) and \( H_1 \otimes H_2 \) must coincide.
	\qed\end{prf}

\section{Inheritance from Kernel to RKHS}
\subsection{Topological Properties of RKHS}
\subsection{Differentiablity of RKHS}

\section{Mercer Representation}
\bibliographystyle{plain}
\bibliography{ref}
\end{document}